> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/BEKuQ8Fq1fpR3H4s02xYzg)

1. 什么是无锁编程
----------

随着计算机技术的发展，多线程技术在开发中越来越重要。在单核时代里，多线程技术通过争抢 CPU 时间片来实现，各个线程是通过排队等待 CPU 执行的，本质上这样的多线程执行方式属于串行执行；随着多核时代的来临，不同线程可以在不同 CPU 内核上执行，这为多线程在多核上并行执行提供了可能。

如今越来越多的应用为了充分利用 CPU 多核的并行计算能力，以提高程序执行效率，开发出了各种各样的多线程框架。比如游戏引擎的多线程渲染框架，比如越来越多的客户端 / 服务器多线程游戏开发框架，再比如最近刚发布正式版的 Unity DOTS 等。这些框架都离不开一个称为 “无锁编程（Lock-free）” 的技术。

通常来说，为了让线程与线程之间的数据交互不会出现数据竞争，会用到互斥锁作为解决方案。而无锁编程和互斥锁的方案不同，它是不通过互斥锁来实现线程和线程之间数据交互的设计方案。

无锁多线程的方案由来已久，这项技术以前更多出现在服务器端。但是随着用户的设备多核能力日益加强，对产品的品质和效率等方面的要求越来越高，在框架层面双端无锁多线程越来越成为一种趋势。这项技术相关的技术资料也不少，本文主要结合游戏客户端相关框架来进行介绍。

那么不使用互斥锁，怎么解决线程之间的数据交互产生的冲突呢？且看下文分解。

2. 为什么使用无锁编程
------------

要回答这个问题，需要讲明白以下两个子问题。

### 2.1. 互斥锁的消耗在哪里

互斥锁本质上作为一个状态值，本身和一个共享资源绑定在一起，逻辑上可以简单将互斥锁理解为如下结构。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRge0N1HTtdDibIvCVAqXyYgFTIoiaZkCWt5gO2GjMoWxmR8cUCFuQXyTg/640?wx_fmt=jpeg&from=appmsg)

在一个 CPU 核上，线程的执行过程中，当代码执行到加锁逻辑时，会根据这个锁的 owner 找到其对应的状态 state 值，之后会进行如下操作：

*   如果 state 是未被锁的状态，则当前 CPU 核正常执行该线程接下来的代码，同时修改 state 值为已被锁的状态，并将状态同步给其他 CPU 核；
    
*   如果 state 是已被锁的状态，则当前 CPU 核不再继续往下执行该线程代码，而是将线程加入等待队列 wait_threads，等待互斥锁退出后重新被调度。
    

在上面第二条操作里 state 被锁的状态下，挂起了当前 CPU 核正在执行的线程外，此时 CPU 核没有事情可做了（也可能在某些系统下会自旋一段时间，忽略这种情况），但是系统不会让它闲置。系统会为 CPU 核找其他活动着的线程的代码来执行，这个过程也被称作 “线程切换”，这个时候就涉及到以下消耗：

*   切换 CPU 上下文的消耗：CPU 当前执行状态下的 CPU 寄存器和程序计数器需要切换成新的值。
    
*   切换线程上下文的消耗：线程当前执行的状态下线程栈、缓存和寄存器需要切换成新的值。
    
*   切换特权模式的消耗：用户态和内核态的切换调用系统指令导致的消耗，比如中断指令。
    

### 2.2. 互斥锁的消耗有多大

首先，使用互斥锁锁住的代码粒度越大，其产生冲突而导致线程切换的可能性越大；锁住的代码粒度越小，产生冲突导致线程切换的可能性越小。因此，互斥锁锁住的代码粒度需要尽可能小，这样就尽可能避免了线程之间的资源竞争情况的出现，也就避免了线程切换。

那么如果产生了线程切换的动作，消耗有多大呢？经过测试，通常消耗在几十纳秒到几微秒之间，这个数值在一般的手机上通常会是一个微秒级的消耗。

> 1 毫秒 = 1000 微秒  
> 1 微秒 = 1000 纳秒

仅看这个消耗的时间数值并不是很大，所以如果调用互斥锁的频率不是很高，也就没必要使用无锁编程。但是越是底层的框架代码，通常被上层调用的次数就会越多，如果使用互斥锁的方案，那么加锁的频率就会非常高，性能消耗也就可能会非常高。这种情况下无锁编程就是一个必要的选择，下面通过例子来说明为什么这种情况下无锁编程是必要的。

例如，渲染引擎通常会有至少一个线程用来生成渲染命令，以及至少一个线程用来处理渲染命令，最终渲染出图像。那么如果线程间的渲染命令传输使用互斥锁，会出现以下问题，让框架设计显得不科学：

*   生成渲染命令的操作可能就是个 “构造 → 赋值 → 入队” 的过程，其消耗的时间可能是纳秒级的，而线程切换却要消耗几微秒；
    
*   在一帧时间（通常是 16.67 毫秒或者 33.33 毫秒）里，可能会调用数千次生成渲染命令的代码，导致仅线程切换的消耗，在极限情况下可能会达到几毫秒。
    

因此，当互斥锁需要锁住的代码粒度是非常小，而且调用次数会很多或者不可控的情况下，就需要考虑使用无锁编程代替互斥锁。

3. 怎么实现无锁编程
-----------

无锁编程有很多实现方案，其通常的实现手段都是通过原子操作代替互斥锁来实现。

### 3.1. 自旋锁

自旋锁（Spin Lock）的本质是一个 `while` 循环，这个循环一直在判断某个条件是否达成，这个条件也就是开发者自定义的锁，当锁的条件满足了之后，就跳出循环继续执行线程接下来的代码。这个锁的的条件通常是一个原子操作，这样保证了在没有互斥锁的情况下，在不同 CPU 核上操作也不会产生冲突。这是最常用的用来代替互斥锁的方案。例如下列伪代码我们可以说它是一种自旋锁。

```
atomic<bool> isLock = false;

void ThreadFunc()
{
    while (isLock) {}
    isLock = true;
    // thread code
    isLock = false;
}
```

但是，如上面代码这样实现的自旋锁性能真的比互斥锁高吗？不一定。要知道即使是一个空的 `while` 循环，CPU 依然是有消耗的，因为这个 CPU 核一直被占用着执行循环代码，所以它一直在忙碌。尤其对于移动平台，这样做会加剧耗电量，这不是一个好的设计。

其实一旦锁开始自旋，就说明当前线程需要等其他线程执行完，这一等至少是就是很多个 CPU 时钟周期，这段时间 CPU 空跑就是浪费。因此，自旋锁除了要一个 `while` 操作模拟等待锁，还需要在循环过程中，让 CPU 核能休息一段时间再重新循环。

那么要如何让 CPU 休息呢？通常通过一些底层指令实现，例如可以用 Intel 提供的 “PAUSE” 指令，通常会让 CPU 休息几十到上百时钟周期。

这个自旋的过程仅发生在 “用户态”，线程一直占有当前执行代码的 CPU 核，没有发生线程切换。

前文提到过无锁编程的使用前提之一是锁住的代码粒度需要非常小，被锁住代码的粒度和不同线程的锁碰撞的几率成正比。被锁住代码的粒度越小，不同线程的锁越不容易碰撞，因此这种锁通常称作**乐观锁**。

### 3.2. 无锁编程的实现

比如为了实现无锁队列（Lock-Free Queue），通常会用到 CAS（Compare And Swap）。这可以视为一个原子操作，且自带 CPU 暂停功能，能让 CPU 休息一段时间，因此适合用作自旋锁。其实现原理如下：

```
// 输入一个pAddr的地址，在函数内部判断其的值是否与期望值nExpected相等
// 如果相等那么就将pAddr的值改为nNew并同时返回true；否则就返回false，什么都不做
bool CAS(int\* pAddr, int nExpected, int nNew)
{
    if(\*pAddr == nExpected)
    {
        \*pAddr = nNew;
        return true;
    }
    else
        return false;
}
```

支持多线程开发的语言一般都会提供 CAS 接口，例如 C# 的 CAS 操作的接口如下：

```
[System.CLSCompliant(false)]
public static UIntPtr CompareExchange (ref UIntPtr location1, UIntPtr value, UIntPtr comparand);
```

这个接口的解释请参看：

那么 CAS 接口如何使用呢？可以参考一下 CAS 在 Unity 的 DOTS 里的应用。在 DOTS 的相关的 C# 源码里，通常用到的容器类都是来自于 Package Manager 里面的 com.unity.collections 包。比如 `NativeQueue`，这是一个线程安全的队列，它的实现是依赖于一个专门为队列设计的对象池 `UnsafeQueueBlockPoolData`，下面看看这个对象池的分配函数的代码。

```
/// <summary>
/// 从对象池里面分配一个对象。这个对象池本质上是一个链表，m\_FirstBlock指向未分配的对象链表的首地址。
/// </summary>
/// <returns>分配的对象</returns>
public UnsafeQueueBlockHeader\* AllocateBlock()
{
    // 通过CAS实现的一个自旋锁：
    // 如果有其他线程正在调用AllocateBlock函数，则自旋等待；
    // 如果没有其他线程调用AllocateBlock函数，则修改m\_AllocLock为1，也就是加锁。
    while (Interlocked.CompareExchange(ref m\_AllocLock, 1, 0) != 0)
    {
    }

    // 第一次赋值checkBlock指向m\_FirstBlock，其中m\_FirstBlock是未分配的对象链表的首地址。
    UnsafeQueueBlockHeader\* checkBlock = (UnsafeQueueBlockHeader\*)m\_FirstBlock;
    UnsafeQueueBlockHeader\* block;

    do
    {
        block = checkBlock;
        // 如果对象池为空，则从内存申请一个对象
        if (block == null)
        {
            Interlocked.Exchange(ref m\_AllocLock, 0);
            Interlocked.Increment(ref m\_NumBlocks);
            block = (UnsafeQueueBlockHeader\*)Memory.Unmanaged.Allocate(m\_BlockSize, 16,
                Allocator.Persistent);
            // 创建新的block后修改m\_AllocLock为0，也就是解锁。
            return block;
        }

        // 如果m\_FirstBlock等于block，则从对象池里弹出block给到上层应用，并且将m\_FirstBlock设置为
        // block->m\_NextBlock。
        checkBlock = (UnsafeQueueBlockHeader\*)Interlocked.CompareExchange(ref m\_FirstBlock,
            (IntPtr)block->m\_NextBlock, (IntPtr)block);
        // 到了这里，如果checkBlock不等于block，也就是说m\_FirstBlock不等于block，那么说明其他线程
        // 在FreeBlock函数里面，修改了m\_FirstBlock的值。此时重新赋值checkBlock为新的m\_FirstBlock
        // ，准备进入下一个循环。
    }
    while (checkBlock != block);

    // 弹出block后修改m\_AllocLock为0，也就是解锁。
    Interlocked.Exchange(ref m\_AllocLock, 0);

    return block;
}
```

以上使用 CAS 只是无锁编程的一种实现方式，其实还有很多方式也能实现无锁编程。例如 Unity 的渲染框架使用的就是 RingBuffer 的方案来实现的无锁编程，其核心思想就是维护两个原子变量，即 RingBuffer 的 Head 位置和 Tail 位置，当这两个原子变量有冲突时，通过一个自旋锁来等待冲突解除。详细请参看下面这篇文章：

4. 多核并行导致的问题
------------

在理解了上文的 3W（What-Why-How）之后，对于写出无锁多线程的代码已经具备了初步理论基础了。但是真正的开发中，可能还会遇到一系列问题，导致运行的结果和预想的不一致。这类问题的主要原因有以下几点。

### 4.1. 缓存一致性问题

要深入了解这个问题，先看一下 CPU 的存储结构。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRyY1iamicUdpV1m27rgYtDp8W5P2iaIibfkpmmFX9NkBicibIeqn7I2vAzs8w/640?wx_fmt=jpeg&from=appmsg)这就是经典的 CPU 三级缓存的架构图，缓存的意义在于用最昂贵、最高速的记忆体来存使用最频繁的数据，用越便宜、越低速的记忆体来存使用越不频繁的数据。

架构图里价钱 & 访问速度的排序是：主内存 < L3 Cache < L2 Cache < L1 d Cache < 寄存器。下表直观地反映了各级记忆体的访问速度。

<table width="751"><thead><tr><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">名称</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">访问速度</th></tr></thead><tbody><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">寄存器</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">300 皮秒</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">L1 d Cache</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">1 纳秒</td></tr><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">L2 Cache &amp; L3 Cache</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">10 纳秒~ 20 纳秒</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">主内存</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">100 纳秒</td></tr></tbody></table>

打个比方来理解这些记忆体以及他们的作用：

主内存好比是图书馆，L3 缓存好比是家里的书架，L2 缓存好比是书桌，L1 缓存好比是人脑的记忆细胞。当一个人坐在书桌前写作，并且遇到了一个问题需要用到某个知识的时候，有以下途径可以获取知识信息：

*   去图书馆查阅：虽然图书馆藏书多，但是去图书馆去查阅知识显然是获取知识最慢的途径；
    
*   去书架上查阅：书架藏书比图书馆少，但是不出家门就能获取到知识，获取速度也比图书馆快；
    
*   去书桌上查阅：书桌上能承载的书比书柜少，但是就在手边，获取信息速度比书架快；
    
*   去脑细胞里查阅：这个用来比喻容量不是很恰当，但是查阅速度几乎是电信号的速度，获取速度极快。
    

因此有的时候，CPU 的一个核心 A 为了 “图方便”，修改过的数据信息就留在自己的 L1 缓存（L1 Cache）里面，暂时不往主内存里面写了，下次用到就不用再去内存里取；而此时，如果核心 B 需要使用这个数据，它去自己 L1 缓存里存里取到的信息和核心 A 的就不一致了，这个时候我们就说**缓存一致性**没有得到保证。这也就导致了本小节开头说的运行结果和预想结果不一致的问题。

### 4.2. 乱序执行问题

乱序执行再细分可以分为：

*   编译器导致的乱序执行；
    
*   CPU 调度导致的乱序执行；
    

### 4.2.1. 编译器导致的乱序执行

开始讲解问题之前，先写一段小程序来做个实验。

```
int a, b, c;

void Func()
{
    a = c + 1;
    b = 1;
}
```

这段代码使用编译器编译的结果是什么样的呢？

第一次选用 x86-64 gcc(trunk) 编译器，不加任何编译选项，结果如下。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRgDJVicluEaibJ7DRSuB9AR8icOgbDXC8IC42cnyMAUvN5YXKuARIOfSbA/640?wx_fmt=jpeg&from=appmsg)第二次选用 x86-64 gcc(trunk) 编译器，加上编译选项 - O2，结果如下。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRl37LvlcVXVoC9TUEdcs6LmwAR6cajIP8gFfwiaRmNX8iaqJRUJgyZXoQ/640?wx_fmt=jpeg&from=appmsg)我们发现两次编译结果主要不同点在于两句代码的执行顺序。

*   在第一次实验里，C++ 代码和汇编代码的执行顺序一致；
    
*   在第二次实验里，C++ 代码和汇编代码的执行顺序不一致。
    

那么为什么会出现这种现象呢？究其根本原因是因为编译器在编译期间，根据它的理解，帮助开发者优化了代码执行顺序。

具体到这个案例来详细解释：

一般 CPU 执行一个指令要经历四到五个流水作业阶段，比如：取指、译码、执行、写回。这几个步骤被 CPU 内部的不同部件执行。

为了更加形象的解释，这里打个比方，这个过程就好比工厂里有一批货物需要加工：

*   加工一个货物需要四个步骤，且需要顺序执行（也就是对同一个货物来说，步骤 1 做完才能做步骤 2，依次类推）；
    
*   工厂里有四个工人，每个工人负责一个步骤（A 工人负责步骤 1，B 工人负责步骤 2，依次类推）。
    

A 工人拿到货物第一时间就可以开工了。接下来，只要有经过步骤 1 处理的货物流向 B 工人，他就可以开工了，否则 B 工人就迟迟不能开工；同理 C 工人和 D 工人也需要等待经过前面步骤处理的货物流向他们。

假如你是车间主任，且假如四个货物加工所消耗的时间不同，你会如何安排工作呢？当然是优先安排耗时短的货物开始加工，这样工人 BCD 能尽快开工。

这个实验也是同样的道理， `b=1` 在编译器看来是一个 CPU 执行周期比 `a=c+1` 短的指令，先执行 `b=1` 可以尽快给流水线 “下游” 的 CPU 部件们“安排工作”，而不至于闲置。

当然，导致编译乱序的情况不光是本案例所说的考虑到 CPU 流水线方面的优化。如果调整执行顺序能让代码更加利于机器执行，只要不影响编译器认为的运行结果，编译器都会去调整代码顺序。例如下面的代码就会被编译器优化。

```
#include <stdlib.h>

int pp[2][3];

void AssignRandomToPP()
{
    for (int j = 0; j < 3; ++j)
    {
        for (int i = 0; i < 2; ++i)
        {
            pp[i][j] = rand();
        }
    }
}
```

对于编译器来说，二维数组和一维数组是一样的，本质都是指针；另外，这段代码还涉及到 cache miss 的缺陷，需要调整 `for` 语句执行顺序。针对这些问题，编译器会把二维数组退化成一维数组来进行优化。

以上这些也就导致了本节开头说的运行结果和预想结果不一致的问题。

### 4.2.2. CPU 调度导致的乱序执行

现在的 CPU 处理器，为了提高内部逻辑部件的利用率，提高运行速度，通常会采用多指令发射、乱序执行等各种措施来进行优化。处理器从 L1 i Cache 预取一批指令，经过前端给到执行引擎里面的调度器，调度器根据指令间的依赖关系，将指令重新排序给到对应的处理单元，以提高处理单元的利用率。

这里稍微扩展一下，指令间的依赖关系通过一个叫做**数据依赖链**（Data Dependency Chain）的概念来判断。数据依赖指的是两句指令之间的一种关系状态，比如后执行的指令使用了先执行指令处理过的值，那么就可以说两条指令之间存在依赖关系。

这种依赖关系在乱序执行方面最大的作用就是：有依赖关系的指令，其相对执行顺序不会被打乱。

归纳下来存在如下三种依赖关系，下面使用代码来直观地理解。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRf4eKYhb53t4XteBvOkhGbMB2keW4Hsw5uK3UHibZibhKQGutUkibQLhKQ/640?wx_fmt=jpeg&from=appmsg)以 4.2.1 里面的那个实验为例，即使是第一次实验，我们不开启编译器的优化选项，它的代码指令进到了 CPU 处理器里面，依然有可能会按照和原始指令不一样的顺序执行，因为 CPU 本身也会乱序调度。

按照上文的分析，用图形的方式直观地看，乱序优化后比乱序优化前 CPU 利用率提高了多少。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRNzd3pgSOeVP0ibVy4roAAzqkCy4ogNxVsnMWPiba20c54VBDkCSsy6lQ/640?wx_fmt=jpeg&from=appmsg)由于 CPU 乱序执行指令的调度方式，也就导致了本节开头说的运行结果和预想结果不一致的问题。

5. 如何解决多核并行导致的问题
----------------

为了解决多核并行问题，硬件提供了一系列解决方案，但是更多的还是需要开发者去提升代码敏感度，利用已有的工具和机制去解决问题。

### 5.1. 缓存一致性协议（MESI）

这是一套复杂的逻辑体系，涉及到许多硬件相关的逻辑结构。本小节尽量在简短的篇幅讲明白和本文主题相关的事情，如有深入探究的需求，请查阅相关资料深入理解。

前文 4.1. 节讨论过多核并行导致的缓存一致性问题，下面用一个动图直观地看一下什么是缓存不一致。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRnbpubCv21pmyjlT3qjjGQ4x8icJDZVloiaoBlgGabxESk2zLgGDzMKKw/640?wx_fmt=jpeg&from=appmsg)为了解决缓存不一致的问题，Intel 提出了 MESI 协议（各 CPU 厂商都有自己的协议解决缓存一致性问题，不过万变不离其宗）。

CPU 缓存里面的数据是以缓存行为单位储存的，Intel 使用缓存行里面的两个 Bit 来记录读写状态，包括修改（Modified）、独占（Exclusive）、共享（Shared）、无效（Invalid）。这四个状态首字母连起来就是 **MESI 协议**名字的来源。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsR1914bQxLSB9BEtCK2K0Yoxg02hO4AKfgoToa0NkvibM0syYHpVGqlRA/640?wx_fmt=jpeg&from=appmsg)这些状态分为两类：

*   一类是表示当前缓存行数据还有效，继续使用就行了；
    
*   一类表示当前缓存行数据无效了，需要重新从内存里读取。
    

下面详细介绍一下这四个状态。

<table width="791"><thead><tr><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">协议</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">有效性</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">说明</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">监听任务</th></tr></thead><tbody><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">修改（Modified）</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">有效</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">缓存数据被自己所在的核修改了</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">如果其他核想要往内存写数据，需要等待当前核先写</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">独占（Exclusive）</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">有效</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">数据只存在于自己核内，其他核的数据都是无效的</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">如果其他核想要读取该缓存行数据，就给它一份，并且双方都把状态改为共享（Share）</td></tr><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">共享（Shared）</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">有效</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">数据在自己核和其他核中都有，且内容是一样的</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">如果其他核将该缓存行状态改为独占（Exclusive），则自己核缓存状态改为无效（Invalid）</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">无效（Invalid）</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">无效</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">缓存数据失效，要想读取该地址的数据需要重新从内存读取</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">不需要监听其他核缓存行的动作</td></tr></tbody></table>

那么这四种状态之间又是如何转换的呢？触发这四种状态的转换，主要通过以下监听行为去触发。

*   监听自己 CPU 内核的操作；
    
*   监听其他 CPU 内核的操作；
    

CPU 要监听的操作包括：

*   本地 cache 读取（local read）：CPU 内核读取自己的本地缓存；
    
*   本地 cache 写入（local write）：CPU 内核写入自己的本地缓存；
    
*   其他 cache 读取（remote read）：其他的 CPU 内核读取了内存中对应当前内核缓存行的数据；
    
*   其他 cache 写入（remote write）：其他的 CPU 内核写入了内存中对应当前内核缓存行的数据；
    

这四种操作引起的状态转换可以用下面这张经典的状态转换图描述，详细过程不再赘述。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRRWDsuSOvj9WYUKsZ8urcOnXbQZBy7a9nwsKSqtsFAUhHuHZvdkLeyA/640?wx_fmt=jpeg&from=appmsg)CPU 通过这些缓存协议，从底层为开发者保证了数据的一致性。

CPU 提供这些一致性协议并不是给开发者直接使用的，但是它确实是在程序底层默默运行着的机制，保证了开发者的程序不会读到各核心都不一致的缓存数据。

### 5.2. 原子操作

前文提到过，无锁编程很大程度上会依赖原子操作，是因为原子操作本身不仅解决了缓存一致性问题，而且原子操作本身就是一种轻量级的锁。因此，原子操作也作为解决多核并行问题的手段之一。

原子操作的原理及其底层实现方式很少有资料能讲明白，通过查阅资料、总结归纳下来有以下两种实现方式。

*   通过锁内存总线来实现：比较早期的 CPU，会通过 LOCK 锁总线的形式来实现。总线被某一个 CPU 核锁住了，内存就只能和这个 CPU 核通信了，这样就保证了操作的原子性。但是这样会有一个问题，总线被某一个 CPU 核锁住了，其他核就只能等待，由于这种锁的粒度太过于粗大，导致性能差。
    

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRmYzXGQD0ln8n5icON8GbZSBw2E6jVwnMn75OdJN9lQgeiajzwwS5icyUA/640?wx_fmt=jpeg&from=appmsg)

*   通过缓存锁来实现：后期的 CPU 在设计上通过缓存一致性协议来实现原子操作。这种实现方式会给每一个需要原子操作的缓存行一个缓存锁，这个缓存锁保证缓存一致性的状态只能是 M 或者 E。其他 CPU 核想要修改同一地址的内存值的话，将会被设为无效。
    

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRhCIibB8a5iaI10MZXVUGQ00ianDWvLpCWQUyXt1qaFhrdiatmKW1tPtvWg/640?wx_fmt=jpeg&from=appmsg)假如在一个多线程程序里面，需要处理的共享变量仅仅只有一个变量，那么在考虑清楚线程调度的情况下设计代码，使用原子操作来处理这个变量，那么这个程序是可以不加锁的，也就是最简单的无锁编程。例如我们上面举的伪代码例子。

```
atomic<bool> isLock = false;

void ThreadFunc()
{
    while (isLock) {}
    isLock = true;
    // thread code
    isLock = false;
}
```

其中共享变量 `isLock` 使用原子操作来处理。

但是如果涉及到多个共享变量，而且他们之间没有数据依赖的关系，会出现什么情况呢？这个问题将在下一小节介绍。

### 5.3. 内存屏障

上一小节说过只有一个共享变量的情况用原子操作基本没问题，但是如果有两个或以上的没有数据依赖关系的共享变量呢？我们来看这样一段伪代码，思考一下这段代码有没有问题。

```
// 在线程1运行的函数
void ThreadFunc1()
{
    a = 1;
    b = 3;
}

// 在线程2运行的函数
void ThreadFunc2()
{
    while (b == 0) continue;

    assert(a == 1);
}
```

关闭编译器的优化选项，实际运行一下，你会发现， `assert(a==1)` 这句话有可能会被触发断言。按代码逻辑，在 `ThreadFunc1` 函数里，先设置的 `a=1`，再设置的 `b=3`，因此在 `ThreadFunc2` 函数里， `b` 不为 `0` 的情况下， `a` 不就应该是 `3` 吗？但是程序却触发断言了，这是什么原因呢？

前文提到过 CPU 执行的指令会出现乱序现象，其实这里就是由于乱序执行导致的。表现上好像内存 / 缓存乱掉了，看着像缓存一致性问题，但其实原因却并不是一样的，这种乱序执行的现象我们叫它**指令重排**。比如上面的代码可能执行顺序是这样的。

<table width="751"><thead><tr><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">步骤</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">ThreadFunc1</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">ThreadFunc2</th></tr></thead><tbody><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">1</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">b = 3;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);"><br></td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">2</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);"><br></td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">while (b == 0) continue;</td></tr><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">3</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);"><br></td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">assert(a == 1);</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">4</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">a = 1;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);"><br></td></tr></tbody></table>

那么用什么方法能避免指令重排呢？其实这小节的标题已经给出了答案，那就是**内存屏障**（也叫内存栅栏）。

什么是内存屏障？通常程序里面出现 “屏障”、“栅栏” 这类词，就是要把某一个执行过程分隔成两个或者多个，其作用主要就是“分隔”，这个分隔的功能跟现实生活中栅栏、围墙、屏障的功能类似，内存屏障就是将内存 / 缓存的读写操作过程进行分隔。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRIzZ2nCvRDzjqlE1HyfNVBpb0PUy2LcogUU8QvMjuNmOXv5jVU5vMNw/640?wx_fmt=jpeg&from=appmsg)首先要知道，缓存和内存之间的操作分为 Store 和 Load 两种。

*   Store：将处理器缓存的数据刷新到内存中。
    
*   Load：将内存存储的数据拷贝到处理器的缓存中。
    

内存屏障就是用来分隔 Store 和 Load 这些内存操作，根据分隔前后的操作类型可以将内存屏障分为以下类型。

<table width="751"><thead><tr><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">屏障类型</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">指令示例</th><th data-style="padding: 0.5rem 1rem; text-align: left; border-top-width: 1px; border-color: rgb(233, 235, 236);">说明</th></tr></thead><tbody><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">LoadLoad 屏障</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">Load 指令 1;LoadLoad 屏障; Load 指令 2;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">确保 [Load 指令 1] 加载数据到缓存之后，[Load 指令 2]以及 [其之后所有 Load 指令] 才能加载数据到缓存。</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">StoreStore 屏障</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">Store 指令 1;StoreStore 屏障; Store 指令 2;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">确保 [Store 指令 1] 写入数据到内存之后，[Store 指令 2]以及 [其之后所有 Store 指令] 才能写入数据到内存。</td></tr><tr><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">LoadStore 屏障</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">Load 指令 1;LoadStore 屏障; Store 指令 2;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">确保 [Load 指令 1] 加载数据到缓存之后，[Store 指令 2]以及 [其之后所有 Store 指令] 才能写入数据到内存</td></tr><tr data-style="background-color: rgb(248, 248, 248);"><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">StoreLoad 屏障</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">Store 指令 1;StoreLoad 屏障; Load 指令 2;</td><td data-style="padding: 0.5rem 1rem; border-color: rgb(233, 235, 236);">确保 [Store 指令 1] 写入数据到内存之后，[Load 指令 2]以及 [其之后所有 Load 指令] 才能加载数据到缓存。</td></tr></tbody></table>

从上表可知内存屏障有两大作用：

*   避免指令重排；
    
*   强制读写内存。
    

因此，本小节开头的例程为了能按程序预期执行，需要加上内存屏障，伪代码如下。

```
// 在线程1运行的函数
void ThreadFunc1()
{
    a = 1;
    // 加入StoreStore屏障
    StoreStoreBarriers();
    b = 3;
}

// 在线程2运行的函数
void ThreadFunc2()
{
    while (b == 0) continue;
    // 加入LoadLoad屏障
    LoadLoadBarriers();
    assert(a == 1);
}
```

以下是虚幻引擎对各平台的内存屏障做的封装。

```
/\*\*
\* Windows implementation of the misc OS functions
\*\*/
struct CORE\_API FWindowsPlatformMisc : public FGenericPlatformMisc
{
    FORCEINLINE static void MemoryBarrier() { \_mm\_sfence(); }
}

/\*\*
 \* Android implementation of the misc OS functions
 \*/
struct CORE\_API FAndroidMisc : public FGenericPlatformMisc
{
    FORCEINLINE static void MemoryBarrier()
    {
        \_\_sync\_synchronize();
    }
}

/\*\*
\* Apple implementation of the misc OS functions
\*\*/
struct CORE\_API FApplePlatformMisc : public FGenericPlatformMisc
{
    FORCEINLINE static void MemoryBarrier()
    {
        \_\_sync\_synchronize();
    }
}

/\*\*
 \* Unix implementation of the misc OS functions
 \*/
struct CORE\_API FUnixPlatformMisc : public FGenericPlatformMisc
{
    FORCEINLINE static void MemoryBarrier()
    {
        \_\_sync\_synchronize();
    }
}
```

### 5.4. 关键字 volatile

关键字 volatile 的作用是什么？网上众说纷纭，总结下来有以下三个功能。

*   防止编译器对 volatile 关键字修饰的变量优化。
    
*   使指令直接对内存进行读写，而不是对缓存。
    
*   防止 CPU 指令重新排序。
    

其实以上三个描述都没有问题，但是针对第二个描述，有一种解释是有错误的。这种解释说，因为多线程访问缓存时候，缓存一致性无法保证，会导致不可预期的错误，因此需要加 volatile 关键字，使指令访问数据时候，直接访问内存里的数据而不是缓存里的数据。这种说法的错误在于，对于那些有缓存一致性协议保证的 CPU，说法是不成立的。

缓存一致性其实是分**强一致性**和**弱一致性**的。

*   强一致性：CPU 内核需要等待修改 Cache 的通知执行结束，才允许执行后续访问指令。
    
*   弱一致性：除非必要，不然 CPU 内核不需要等待所有 Cache 通知执行结束。
    

一般的 CPU 缓存一致性协议的确采用的是弱一致性策略，因为强一致性策略对性能影响太大，但是弱一致性并非一致性无法保证。CPU 的弱一致性是指在 CPU 核内部的实现上可能出现缓存不一致，但是表现给上层的程序逻辑，一定是强一致性的。也就是说开发者写的代码是感知不到缓存不一致的，如果这么轻易就让程序感知到缓存不一致，那这样的缓存一致性协议存在的意义是什么呢？

推荐一个网站，可以去直观地体验一下 MESI 的工作原理，上层逻辑是不可能 Read 到不一致的缓存数据的。

然而，在代码层面，的确会存在不同线程间数据不一致的问题，那这又是因为什么造成的呢？换句话说，为什么要使用 volatile 关键字呢？这就得说到 MESI 其实有个缺陷，那就是当缓存不一致的情况下，为了同步不同核之间的缓存数据，是有可能让一个 CPU 内核等待正确的缓存值的，这个等待的过程就对 CPU 内核形成了阻塞。但是 CPU 还有一个机制——指令重排，为了尽量避免阻塞导致的性能问题，CPU 调度器会重排执行指令，调度其他无依赖的指令来执行，导致本该写入缓存的操作被延后了。volatile 关键字就是为了让 CPU 不要重排指令而使用的关键字。VivioJS MESI help 然而，在代码层面，的确会存在不同线程间数据不一致的问题，那这又是因为什么造成的呢？换句话说，为什么要使用 volatile 关键字呢？这就得说到 MESI 其实有个缺陷，那就是当缓存不一致的情况下，为了同步不同核之间的缓存数据，是有可能让一个 CPU 内核等待正确的缓存值的，这个等待的过程就对 CPU 内核形成了阻塞。但是 CPU 还有一个机制——指令重排，为了尽量避免阻塞导致的性能问题，CPU 调度器会重排执行指令，调度其他无依赖的指令来执行，导致本该写入缓存的操作被延后了。volatile 关键字就是为了让 CPU 不要重排指令而使用的关键字。

经过查阅资料，了解到有些语言的 volatile 的实现原理，其实内部是用内存屏障实现的，那么结合 5.3. 小节，就很好理解为什么 volatile 关键字会避免重排指令了，同时也解释了 volatile 为什么会让指令直接读写内存，因为内存屏障的作用就是这些。

下面通过两个小节，来看一下 volatile 的使用示例。

### 5.4.1. 防止编译器优化

比如我们要测试空的 `for` 循环的消耗，如果按如下代码书写将可以达到我们的目的。

```
void Func()
{
    // 开始计时
    auto beginTime = std::chrono::high\_resolution\_clock::now();

    // 调用10000次for循环
    for (volatile int j = 0; j < 10000; ++j);

    // 结束计时
    auto endTime = std::chrono::high\_resolution\_clock::now();
    // 计算时间消耗
    auto timeInterval = std::chrono::duration\_cast<std::chrono::milliseconds>(endTime - beginTime);
    // 打印时间消耗
    std::cout << timeInterval.count() << "ms\n";
}
```

如果去掉代码第 7 行的 volatile，将会得到以下编译结果。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIfl7vXI1NCQQXE9vhibscdsRumibFGZuE80vepfCVpxfZhBHmlySaZOYvMxXkbY9AJBvU586wbYLcicQ/640?wx_fmt=jpeg&from=appmsg)可见编译器忽略了空的 `for` 循环，没有为其生成任何汇编代码，也就无法测出正确的 `for` 循环消耗了。

### 5.4.2. CPU 指令重排

如果在 Unity 里要实现一个线程安全的单例模式怎么做呢？请看如下代码。

```
public sealed class Singleton
{
    // 单例实例
    private static volatile Singleton instance = null;

    // 锁class用的对象，线程安全用
    private static object syncRoot = new object();

    private Singleton() {}

    public static Singleton Instance
    {
        get
        {
            // 一次判空。如果这次判断不为空，就不必再执行加锁了，避免加锁的消耗
            if (instance == null)
            {
                lock (syncRoot)
                {
                    // 二次判空。作为临界值进行判空，这次判空是必要的。
                    if (instance == null)
                    {
                        instance = new Singleton();
                    }
                }
            }
            return instance ;
        }
    }
}
```

本例程是典型的线程安全单例模式，虽然这是带互斥锁的代码，但是不影响我们理解关键字 volatile。

如果将代码第 4 行的 `volatile` 去掉，会发生什么事情呢？如果 A 线程此时运行到代码第 16 行，将要去读取 `instance` 变量，而 B 线程运行到代码 23 行的 `instance=newSingleton()` 赋值语句。此时赋值后的 CPU 缓存要同步数据给 A 线程所在的 CPU 缓存，CPU 觉得这个操作阻塞太影响执行效率，就可能会调度 A、B 线程继续执行。此时如果 B 线程继续执行退出了 `syncRoot` 的作用域，并且 A 线程继续执行代码第 16 行，发现 `instance` 还是 `null`，A 线程就继续执行到代码第 18 行的加锁逻辑。你会发现， `Singleton` 的构造函数被重复调用了，这就导致其实线程不安全了。

### 5.5. C++ 内存序

大部分支持多线程编程的语言都会提供一些保证内存顺序的接口，最基本的比如内存屏障、volatile 关键字等。其中 C++11 的内存序控制是比较复杂和精细的，所以专门开了一个小节来介绍。

为什么 C++ 的要引入内存序接口？思考一个问题，如果我们有大量的内存读写操作，尤其是有大量原子读写操作，如果全部操作都不允许指令重排，也就是严格保证顺序一致性，虽然运行结果很容易符合开发者编程预期，降低了开发难度，但是这样会很大程度影响 CPU 执行性能，因为前文介绍过，保证缓存一致性是需要阻塞等待缓存同步的。C++ 通过引入内存序接口，提供了控制 CPU 缓存同步的能力给开发者，让内存读写的顺序更加灵活可控。C++ 的内存序允许按照批次保证内存读写顺序，而不必对每一个读写操作保证，也就是说批次和批次之间保持顺序一致性，批次内部保持松散顺序就行。当然 C++ 也可以完全不保证内存读写顺序，以提高程序执行效率。

C++ 提供了 6 种内存序：

```
typedef enum memory\_order
{
    memory\_order\_relaxed,
    memory\_order\_acquire,
    memory\_order\_release,
    memory\_order\_consume,
    memory\_order\_acq\_rel,
    memory\_order\_seq\_cst,
} memory\_oder;
```

以上六种内存序通常用在原子操作、内存屏障、缓存读写等需要保证内存顺序的接口上，当作其参数。这些接口通常都以 `std::memory_order_seq_cst` 作为默认参数。例如以下例程。

```
// 原子操作写入
isLock.store(true, std::memory\_order\_seq\_cst);
// 原子操作读取
isLock.load(std::memory\_order\_seq\_cst);
// 内存屏障
std::atomic\_thread\_fence(std::memory\_order\_seq\_cst);
// CAS
head.compare\_exchange\_weak(n, next, std::memory\_order\_seq\_cst);
```

这六种内存序有以下四种组织形式是比较常用的。

### 5.5.1. 松散序列（relaxed）

**memory_order 枚举值**： `std::memory_order_relaxed`。

**底层实现**：底层实现自由内存读写顺序。

**说明**：使用这种内存序的多个内存操作之间同一个线程里还是按照 happens-before 的关系执行，但是不同线程之间的执行关系是任意的。

**性能**：这种内存序因为对内存读写顺序的控制很弱，所以执行效率是最高。

```
atomic<int> guard(0);
int payload = 0;

// 在线程1运行的函数
void ThreadFunc1()
{
    payload = 42;
    guard.store(1, std::memory\_order\_relaxed);
}

// 在线程2运行的函数
void ThreadFunc2()
{
    if (guard.load(std::memory\_order\_relaxed) != 0)
    {
        p = payload;
    }
}
```

由于松散内存序是不保证内存读写顺序的，所以最终 `p` 的值可能是 `0` 也有可能是 `42`。

### 5.5.2. 顺序一致序列（sequential consistency）

**memory_order 枚举值**： `std::memory_order_seq_cst`。

**底层实现**：同时使用了 StoreStore 屏障和 LoadLoad 屏障来实现，因此保证了内存读写顺序和指令顺序一是致的。

**说明**：使用这种内存序保证了无论在内存操作的顺序，都严格按照指定的顺序来执行。

**性能**：这种内存需要严格控制每一次内存读写的顺序，所以执行效率是所有内程序里最低的。

```
atomic<int> guard(0);
int payload = 0;

// 在线程1运行的函数
void ThreadFunc1()
{
    payload = 42;
    guard.store(1, std::memory\_order\_seq\_cst);
}

// 在线程2运行的函数
void ThreadFunc2()
{
    if (guard.load(std::memory\_order\_seq\_cst) != 0)
    {
        p = payload;
    }
}
```

顺序一致性序列是完全保证内存读写顺序和指令顺序一致的，所以最终的 `p` 值为 `42`。

### 5.5.3. 获取 - 释放序列（acquire-release）

**memory_order 枚举值组合**： `std::memory_order_release` 和 `std::memory_order_acquire`。

**底层实现**：

`std::memory_order_release` 底层使用了 StoreStore 屏障，保证在此内存操作之前的所有 Store 操作都不可能重排到此操作之后；也可以理解为这个操作使 CPU 将所有缓存写入了内存，使其他缓存可见。

`std::memory_order_acquire` 底层使用了 LoadLoad 屏障，保存在此内存操作之后的所有 Load 操作都不可能重排到此操作之前；也可以理解为这个操作使 CPU 将所有抛弃了所有缓存，重新从内存读取数据。

**说明**：使用这种内存序，保证了 `std::memory_order_release` 之前的 Store 操作按一个批次同步到其他缓存，同时 `std::memory_order_acquire` 之后的 Load 操作按一个批次从内存加载数据到缓存，保证了局部的一致性。

**性能**：这种内存序因为是按批次来同步缓存的，所以性能优于顺序一致性序列，但是又没有松散序列高效。

```
atomic<int> guard(0);
int payload = 0;

// 在线程1运行的函数
void ThreadFunc1()
{
    payload = 42;
    guard.store(1, std::memory\_order\_release);
}

// 在线程2运行的函数
void ThreadFunc2()
{
    if (guard.load(std::memory\_order\_acquire) != 0)
    {
        p = payload;
    }
}
```

获取 - 释放序列保证写线程写完之后，读线程才开始读的局部一致性，所以最终的 `p` 值为 `42`。

### 5.5.4. 数据依赖序列（data dependency）

**memory_order 枚举值组合**： `std::memory_order_release` 和 `std::memory_order_consume`。

**底层实现**： `std::memory_order_consume` 的底层实现并不使用内存屏障，而是分析数据依赖来保证数据依赖链上的指令的顺序一致性。

**说明**：在从内存加载数据到缓存的时候，根据数据依赖链的顺序去加载。写入内存还是使用 `std::memory_order_release` 的策略不变。这种内存序在多平台方面，支持不是很好，有一些硬件设备并不支持这种内存序列，因此它会被退化成获取 - 释放序列。

**性能**：这种内存序因为不再使用内存屏障，因此性能好于获取 - 释放序列，但依然没有松散序列高效。

```
atomic<int\*> guard(nullptr);
int payload = 0;

// 在线程1运行的函数
void ThreadFunc1()
{
    payload = 42;
    guard.store(&playload, std::memory\_order\_release);
}

// 在线程2运行的函数
void ThreadFunc2()
{
    int\* g = guard.load(std::memory\_order\_consume);
    if (g != nullptr)
    {
        p = \*g;
    }
}
```

由于 guard、g 和 p 都是同一条数据依赖链上的数据，因此最终的 `p` 值为 `42`。

6. 总结
-----

游戏相关的框架越来越多的在利用多核 CPU 带来的性能提升，但是如果利用不当，可能会适得其反，无锁多线程编程能很好解决其中的一部分问题。本文着重介绍了无锁多线程的原理，作为多线程开发基础的一种积累。但其实无锁多线程编程是一项复杂的技术，它要求开发者对硬件工作原理有一定了解，对数据及数据间的关系有足够的敏感度，对线程间的执行顺序由足够的把控力等。在本文基础上，对无锁多线程的编程还需要更加深入的理解和更多的实践。

<table interlaced="enabled" align="center"><tbody><tr data-style=""><td valign="middle" align="left" colspan="1" rowspan="1"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247513119&amp;idx=1&amp;sn=ac7715c90ad005e2990e7c2efec62876&amp;chksm=f9010665ce768f7321d345edfe1864cbfdda170d2613a019709e54cd02d8f3e8fb4750b46d3c&amp;scene=21#wechat_redirect" textvalue="收藏转发，GPU、CPU、内存等150+游戏开发性能分析优化干货合集！" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" data-style="text-decoration: underline; letter-spacing: 0.578px; text-align: -webkit-left; text-wrap: wrap; background-color: rgb(252, 252, 252); min-height: 1em; font-size: 14px;">收藏转发，GPU、CPU、内存等 150 + 游戏开发性能分析优化干货合集！</a></td></tr><tr data-style=""><td width="511" valign="middle" align="left"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247512555&amp;idx=1&amp;sn=8a98f83843a035ddc89b17e2cbeb6a1f&amp;chksm=f9010391ce768a87f4789be4c4b6e342a669edcadd33f14762535d67414341be1943368c6e69&amp;scene=21#wechat_redirect" textvalue="非广告！6年老号福利，描边、景深、泛光、投影等60+游戏后处理效果实现合集！" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">非广告！6 年老号福利，描边、景深、泛光、投影等 60 + 游戏后处理效果实现合集！</a><br></td></tr><tr data-style=""><td width="511" valign="top"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247511897&amp;idx=1&amp;sn=3f14b6405fe583a24f70169ae8863fd8&amp;chksm=f9011d23ce7694352cdbfe6b7fc45171410f7c2d4f1f3a0dc6745bd25e5b79137ee0cc191a30&amp;scene=21#wechat_redirect" textvalue="收藏转发！原神、只狼、战神4等80+游戏渲染效果技术实现研究合集！免费！" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">收藏转发！原神、只狼、战神 4 等 80 + 游戏渲染效果技术实现研究合集！免费！</a><br></td></tr><tr data-style=""><td width="511" valign="top"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247487026&amp;idx=1&amp;sn=442efa67e68f323aaa2e2077f80ecce9&amp;chksm=f902bc48ce75355ed8fd99975c1964c3e38455ad6ba36086be7e8cb6ea2797e973b05cafda85&amp;scene=21#wechat_redirect" textvalue="Unity3D游戏开发中100+效果的实现和源码大全 - 收藏起来肯定用得着" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Unity3D 游戏开发中 100 + 效果的实现和源码大全 - 收藏起来肯定用得着</a><br></td></tr><tr data-style=""><td width="511" valign="top"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247506542&amp;idx=1&amp;sn=f8322d9ad4821ff9709be0ad8a4eb206&amp;chksm=f9016814ce76e102acdb37bd57017cb86d3732dfb430a0f03d1f64b59e16e7b231d9fc92e18d&amp;scene=21#wechat_redirect" textvalue="【原神】各角色Pixiv涩图统计(一). 最多的是谁? R18涩图谁最多?" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">【原神】各角色 Pixiv 涩图统计 (一). 最多的是谁? R18 涩图谁最多?</a><br></td></tr><tr data-style=""><td width="511" valign="top"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzUxMDM3MTYwNQ==&amp;mid=2247503967&amp;idx=1&amp;sn=1535132037c48015d6e7483a5524531e&amp;chksm=f9016225ce76eb33bca178a8260356fd0a99f4c555a38ce80df3cbc5ba2aef7091fb066fd075&amp;scene=21#wechat_redirect" textvalue="战神4角色绑定与过场动画制作" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">战神 4 角色绑定与过场动画制作</a><br></td></tr></tbody></table>  

_声明：__发布此文是出于传递更多知识以供交流学习之目的。若有来源标注错误或侵犯了您的合法权益__，请作者持权属证明与我们联系，我们将及时更正、删除，谢谢。_

  

_鸣谢：感谢各位作者的授权转载，欢迎大家投稿，一起分享交流游戏开发技术。_

_作者：zd304_

_原文：https://zhuanlan.zhihu.com/p/646244755_

**关注**【GameDevLearning】  

游戏开发技术、技巧、教程和资源，答疑解惑，内推面试

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/l2Uzl9GfAIdkUW35qje5yVS0c19IW5OKIUzSBiaFy76Jnglwy7gC1czsTF5A2VW8Bm9UqqGBibscnkPibyqcKUkCA/640?wx_fmt=jpeg)